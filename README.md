# Welcome to my_mr_clean project

## Task
The task of this code is to analyze the frequency of words in a Wikipedia article. It involves retrieving the content of a specified Wikipedia page, tokenizing it, and then calculating the frequency of each word. Additionally, the code provides functionality to filter out common English stop words for more accurate analysis.
## Description
Suppose we want to analyze the frequency of words in the Wikipedia article about the "Ozone layer". After running the script, it will provide insights into the most frequent words in the article, helping to understand its content better.
## Installation
To install the necessary dependencies, execute the following command:
```bash
pip install -r requirements.txt
```
## Usage
Run the code provided in the my_mr_clean.py script.